#version 460 core
#extension GL_GOOGLE_include_directive : enable

#include "./includes.glsl"

layout (local_size_x = BLOCK_SIZE) in;

shared uint localHistogram[RADICES];

// wide of 128 elements, each element should be in uint16_t, but for compatibility used uint32_t
shared uint_rdc_wave_lcm _data[Wave_Size];
shared blocks_info blocks;
#define key _data[Lane_Idx]

initSubgroupIncFunctionTargetQuad(localHistogram[WHERE], countOffset, 1, uint, uvec4)

#define bcount blocks.count

void main() {
    const uint Radice_Idx = gl_WorkGroupID.y * Wave_Count_RX + Wave_Idx;
    //const uint Radice_Idx = gl_WorkGroupID.y + Wave_Idx * gl_NumWorkGroups.y;

    // set prefix sum (planned distribute threads) 
    [[unroll]]
    for (uint rk=0u;rk<RADICES;rk+=WRK_SIZE_RT) {
        const uint radice = uint(rk + Radice_Idx);
        [[flatten]] if (radice < RADICES) localHistogram[radice] = PrefixSum[radice + gl_WorkGroupID.x * RADICES];
    }
    if (Local_Idx == 0) blocks = get_blocks_info(push_block.NumKeys), bcount = min(tiled(blocks.count, 4u), 524288u);
    LGROUP_BARRIER
    IFALL (bcount <= 0) return;

    // calculate blocks
    WPTR4 addr = WPTR4(0,1,2,3)*Wave_Size_RT.xxxx + WPTR(blocks.offset).xxxx + WPTR4(Lane_Idx.xxxx);

    [[unroll, dependency_length(4)]]
    for ( uint wk = 0; wk < bcount; wk++ ) {
        bvec4 validAddress = lessThan(addr, blocks.limit.xxxx);
        [[flatten]] IFALL(all(not(validAddress))) break;

        [[flatten]] if (Wave_Idx == 0) {
            key = uint_rdc_wave_lcm(p4x_8(uvec4(
                BFE(validAddress.x ? KeyIn[addr.x] : OutOfRange, (push_block.Shift)*BITS_PER_PASS, BITS_PER_PASS),
                BFE(validAddress.y ? KeyIn[addr.y] : OutOfRange, (push_block.Shift)*BITS_PER_PASS, BITS_PER_PASS),
                BFE(validAddress.z ? KeyIn[addr.z] : OutOfRange, (push_block.Shift)*BITS_PER_PASS, BITS_PER_PASS),
                BFE(validAddress.w ? KeyIn[addr.w] : OutOfRange, (push_block.Shift)*BITS_PER_PASS, BITS_PER_PASS)
            )));
        }
        LGROUP_BARRIER

        // WARP-optimized histogram calculation
        [[unroll]]
        for (lowp uint rk=0u;rk<RADICES;rk+=WRK_SIZE_RT) {
            const lowp uint radice = uint(rk + Radice_Idx);
            const bvec4 owned = and(equal(up4x_8(key), radice.xxxx), validAddress);
            [[flatten]] if (any(owned)) {
                WPTR4 offset = WPTR4(countOffset(uint(radice), owned));
                [[flatten]] if (owned.x) { ValueTmp[offset.x] = ValueIn[addr.x], KeyTmp[offset.x] = KeyIn[addr.x]; }
                [[flatten]] if (owned.y) { ValueTmp[offset.y] = ValueIn[addr.y], KeyTmp[offset.y] = KeyIn[addr.y]; }
                [[flatten]] if (owned.z) { ValueTmp[offset.z] = ValueIn[addr.z], KeyTmp[offset.z] = KeyIn[addr.z]; }
                [[flatten]] if (owned.w) { ValueTmp[offset.w] = ValueIn[addr.w], KeyTmp[offset.w] = KeyIn[addr.w]; }
            }
            [[flatten]] IFALL (all(or((radice >= RADICES).xxxx, or(owned, not(validAddress))))) break;
        }

        LGROUP_BARRIER
        //addr += Wave_Size_RT<<1;
        addr += Wave_Size_RT<<2;
    }

    //LGROUP_BARRIER
}
